{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10975091,"sourceType":"datasetVersion","datasetId":6829321}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T01:46:18.369956Z","iopub.execute_input":"2025-03-10T01:46:18.370213Z","iopub.status.idle":"2025-03-10T01:46:18.810196Z","shell.execute_reply.started":"2025-03-10T01:46:18.370183Z","shell.execute_reply":"2025-03-10T01:46:18.809028Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv('/kaggle/input/dataset1/qa_pairs.csv')  \nprint(\"Dataset size:\", len(df))\n\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\nprint(\"Training set size:\", len(train_df))\nprint(\"Test set size:\", len(test_df))\n\ntrain_df.to_csv('train.csv', index=False)\ntest_df.to_csv('test.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T01:49:28.416270Z","iopub.execute_input":"2025-03-10T01:49:28.416629Z","iopub.status.idle":"2025-03-10T01:49:29.138679Z","shell.execute_reply.started":"2025-03-10T01:49:28.416597Z","shell.execute_reply":"2025-03-10T01:49:29.137594Z"}},"outputs":[{"name":"stdout","text":"Dataset size: 343\nTraining set size: 274\nTest set size: 69\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nimport torch\nfrom torch.utils.data import Dataset\n\nmodel_name = \"Qwen/Qwen2.5-3B-Instruct\" \ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n\n\ndef format_prompt(row):\n    return f\"Question: {row['Question']}\\nAnswer: {row['Answer']}\\n\"\n\n\nclass QADataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=512):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        prompt = format_prompt(row)\n        inputs = self.tokenizer(prompt, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n        input_ids = inputs.input_ids.squeeze()\n        attention_mask = inputs.attention_mask.squeeze()\n        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n\ntrain_dataset = QADataset(train_df, tokenizer)\neval_dataset = QADataset(test_df, tokenizer)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./qwen_finetuned\",\n    overwrite_output_dir=True,\n    num_train_epochs=1,         \n    per_device_train_batch_size=1,  \n    per_device_eval_batch_size=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    save_steps=100,\n    logging_steps=25,\n    learning_rate=2e-5,\n    fp16=True,                 \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\ntrainer.train()\n\ntrainer.save_model(\"qwen_finetuned_model\")\ntokenizer.save_pretrained(\"qwen_finetuned_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T01:51:05.693002Z","iopub.execute_input":"2025-03-10T01:51:05.693370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95027f3b4afc47bda925971055b24a54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd02d8887c134366b245b1cbdfc73764"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19be9f7982884d53a4c514fd222e856e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02747b9030594002a12820f7aa5cb8a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f47db423aa44cdea28b0f55dc32ecf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52238682ff4c4409825a7a215417c462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c331ad48c074bbcb4ca13712707bba8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086b4fc6a9d64255bc6a01a8590fce3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee763f2969d744cbbf37ea66b4a6ef33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d968a56dc989479ebac8f796dd027da9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a27b25996f6c45efb8ebbe8ae2c0a3f4"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}